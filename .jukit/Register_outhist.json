{"QmmjrfLpJ4": [{"output_type": "stream", "name": "stdout", "text": "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                           Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 136\u001b[0m\n\u001b[1;32m    132\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m vit\u001b[38;5;241m.\u001b[39mload_data(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, faiss_index_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaiss_index.faiss\u001b[39m\u001b[38;5;124m'\u001b[39m, metadata_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaiss_index_metadata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m#features = vit.extract_features(images)\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#vit.build_and_save_faiss_index(features, save_path='faiss_index') #if file is not exist, you have to train index for images\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Test recognition\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m result, score \u001b[38;5;241m=\u001b[39m vit\u001b[38;5;241m.\u001b[39mrecognize_face_1(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_img/Long/cropped_face_10.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecognized: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\nCell \u001b[0;32mIn[1], line 95\u001b[0m, in \u001b[0;36mViTFaceRecognition.recognize_face_1\u001b[0;34m(self, query_img_path, threshold)\u001b[0m\n\u001b[1;32m     92\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(cv2\u001b[38;5;241m.\u001b[39mimread(query_img_path), cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     93\u001b[0m query_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features([img])\n\u001b[0;32m---> 95\u001b[0m D, I \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39msearch(query_embed\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m), k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     96\u001b[0m distance \u001b[38;5;241m=\u001b[39m D[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     97\u001b[0m pred_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[I[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\n\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'search'\n"}]}